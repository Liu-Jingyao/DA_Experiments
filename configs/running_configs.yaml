# global params

environment: 'beijing' # vpn, local, quanzhou, neimeng, beijing
batch_size: 32 # 32
map_batch_size: 1000
eval_steps: 200 # 1000/200
logging_steps: 100 # 100/100
ignore_cache: true
repeat_num: 3

---
# single test config

default:
  dataset: 'rotten_tomatoes' # imdb, rotten_tomatoes, yelp-5, amazon-5
  model: 'lstm' # cnn, distilbert, lstm
  augmentations: ['pred_loss_replacement'] # keyword_enhance, random_word_dropout, tfidf_word_dropout, synonym_replacement,
                                        # random_deletion, random_swap, random_insertion,
                                        # hidden_state_pooling, hidden_state_cnn, online_random_replacement, pred_loss_replacement
  aug_params: [0.5] #0.005, dont remain blank, 0.5
  epochs: 10

---
# workflow test config
training_config:
  distilbert:
    imdb:
        epochs: 2
    sst-2:
        epochs: 2
    rotten_tomatoes:
        epochs: 2
    amazon-5:
        epochs: 2
    yelp-5:
        epochs: 2
  roberta:
    imdb:
        epochs: 2
        batch_size: 16
    sst-2:
        epochs: 2
    rotten_tomatoes:
        epochs: 2
    amazon-5:
        epochs: 2
        batch_size: 16
    yelp-5:
        epochs: 2
        batch_size: 16
  albert:
    imdb:
        epochs: 2
        batch_size: 16
    sst-2:
        epochs: 2
    rotten_tomatoes:
        epochs: 2
    amazon-5:
        epochs: 2
        batch_size: 16
    yelp-5:
        epochs: 2
        batch_size: 16
  xlnet:
    imdb:
        epochs: 2
        batch_size: 16
    sst-2:
        epochs: 2
    rotten_tomatoes:
        epochs: 2
    amazon-5:
        epochs: 2
        batch_size: 16
    yelp-5:
        epochs: 2
        batch_size: 16
  electra:
    imdb:
        epochs: 2
        batch_size: 16
    sst-2:
        epochs: 2
    rotten_tomatoes:
        epochs: 2
    amazon-5:
        epochs: 2
        batch_size: 16
    yelp-5:
        epochs: 2
        batch_size: 16
workflow_config:
  synonym_replacement:
    models: [ distilbert, roberta, albert ]
    datasets: [ rotten_tomatoes ]
    prob: 0.1
#  online_random_replacement:
#    models: [ distilbert, roberta, albert ]
#    datasets: [ rotten_tomatoes ]
#    prob: 0.05
  pred_loss_replacement:
    models: [ distilbert, roberta, albert ]
    datasets: [ rotten_tomatoes ]
    prob: 0.1